{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Pandas - G5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programa com o intuito de treinar ferramentas do Pandas e realizar análise de dados com diferentes bases.\n",
    "Let's Code.\n",
    "\n",
    "Dados utilizados:\n",
    "- CSV Dados Demográficos \n",
    "- CSV Renda e Gastos\n",
    "- CSV Bens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from argparse import ArgumentParser\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "# Definir o caminho da pasta em que o projeto se encontra\n",
    "folder_class_path = os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------- Tarefa 1 --------------------------------------------------------- #\n",
    "# Função com o objetivo de receber as bases de dados csv\n",
    "def receber_bases():\n",
    "    df_demografico = pd.read_csv(folder_class_path + '/1_demografico.csv', sep=';', encoding='utf-8-sig')\n",
    "    df_renda_gastos = pd.read_csv(folder_class_path + '/2_renda_gastos.csv', sep=';', encoding='utf-8-sig')\n",
    "    df_bens = pd.read_csv(folder_class_path + '/3_bens.csv', sep=';', encoding='utf-8-sig')\n",
    "    \n",
    "    return df_demografico, df_renda_gastos, df_bens\n",
    "\n",
    "\n",
    "# Função para junção das bases de dados\n",
    "def unificar_bases(df_demografico, df_renda_gastos, df_bens):\n",
    "    # O merge é realizado de forma interna\n",
    "    df_unificado = df_demografico.merge(df_renda_gastos, how='inner')\n",
    "    # É preciso utilizar ambos os index como chaves para se tornar interno\n",
    "    df_unificado = df_unificado.merge(df_bens, left_index=True, right_index=True)\n",
    "    \n",
    "    return df_unificado\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------- Tarefa 2 --------------------------------------------------------- #\n",
    "\n",
    "# Função para criar o relatório de variáveis quantitativas\n",
    "def criar_relatorio_geral(df_unificado):\n",
    "    # Receber os valores estatísticos da função describe\n",
    "    df_relatorio = df_unificado.describe().T.sort_index()\n",
    "    # Remover as colunas qualitativas, mas que contém números e devem ser desconsideradas\n",
    "    columns_drop = ['count', 'std', '50%']\n",
    "    index_drop = ['ID', 'Agricultural Household indicator', 'Electricity']\n",
    "    df_relatorio.drop(index=index_drop, columns=columns_drop, inplace=True)\n",
    "\n",
    "    # Calcular a métrica faltante da mediana\n",
    "    df_relatorio['median'] = calcula_mediana(df_unificado, df_relatorio.index.values)\n",
    "\n",
    "    # Reordenar as colunas e devolver o DataFrame\n",
    "    columns_order = ['min', '25%', 'median', '75%', 'max', 'mean']\n",
    "    df_relatorio = df_relatorio[columns_order]\n",
    "    \n",
    "    return round(df_relatorio, 3)\n",
    "\n",
    "\n",
    "# Função para retornar a mediana de uma coluna quantitativa de DataFrame\n",
    "def calcula_mediana(df_unificado, colunas_qualitativas):\n",
    "    serie_mediana = []\n",
    "    for coluna in colunas_qualitativas:\n",
    "        serie_mediana.append(df_unificado[coluna].median())\n",
    "    \n",
    "    return serie_mediana\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------------- #     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------- Tarefa 3 e 4--------------------------------------------------------- #\n",
    "\n",
    "# Função para remoção dos Outliers\n",
    "def criar_relatorio_sem_outlier(df_unificado, opcao_tratar_outlier='remover'):\n",
    "    # Definir a séire de medianas do DataFrame\n",
    "    median = df_unificado.median()\n",
    "\n",
    "    # Resumir somente as colunas com dados numéricos\n",
    "    df_unificado = criar_df_quantitativo(df_unificado)\n",
    "    \n",
    "    # Agora, para as colunas restantes é preciso tratar os outliers (remover ou trocar pela mediana)\n",
    "    for coluna in df_unificado.columns:\n",
    "        df_unificado.loc[:, coluna] = tratar_outliers(df_unificado[coluna])\n",
    "    \n",
    "    # Para a opção de resolver os outliers com a mediana em vez de deixar vazio\n",
    "    if opcao_tratar_outlier != 'remover':\n",
    "        for column in df_unificado.columns:\n",
    "            df_unificado[column].fillna(median[column],inplace=True)\n",
    "   \n",
    "    # Criar o DataFrame de relatório a partir do DF de dados\n",
    "    df_relatorio_sem_outlier = df_unificado.describe().T.sort_index()\n",
    "    # Remover as colunas qualitativas, mas que contém números e devem ser desconsideradas\n",
    "    columns_drop = ['count', 'std', '50%']\n",
    "\n",
    "    # Calcular a métrica faltante da mediana\n",
    "    df_relatorio_sem_outlier['median'] = calcula_mediana(df_unificado, df_relatorio_sem_outlier.index.values)\n",
    "\n",
    "    # Reordenar as colunas e devolver o DataFrame\n",
    "    columns_order = ['min', '25%', 'median', '75%', 'max', 'mean']\n",
    "    df_relatorio_sem_outlier = df_relatorio_sem_outlier[columns_order]\n",
    "\n",
    "    return round(df_relatorio_sem_outlier, 3)\n",
    "\n",
    "# Resumir somente as colunas com dados numéricos\n",
    "def criar_df_quantitativo(df_unificado):\n",
    "    df_unificado = df_unificado.select_dtypes(include=np.number)\n",
    "\n",
    "    # Definir as colunas qualitativas que se utilizam de variáveis numéricas para que sejam excluídas \n",
    "    colunas_drop = ['ID', 'Agricultural Household indicator', 'Electricity']\n",
    "    df_unificado.drop(columns=colunas_drop, inplace=True)\n",
    "    return df_unificado\n",
    "\n",
    "# Função para tratar os outliers da coluna em análise do DataFrame\n",
    "def tratar_outliers(serie_coluna):\n",
    "    q1 = np.percentile(serie_coluna, 25)\n",
    "    q3 = np.percentile(serie_coluna, 75)\n",
    "    delta_outlier = 1.5*(q3 - q1)\n",
    "    \n",
    "    serie_coluna_outlier_tratado = serie_coluna.apply(lambda x: aplicar_metodo_tuckey(q1, q3, delta_outlier, x))\n",
    "\n",
    "    return serie_coluna_outlier_tratado\n",
    "\n",
    "# Função para aplicar o método de Tuckey e avaliar se o dado analisado é outlier ou não\n",
    "def aplicar_metodo_tuckey(q1, q3, delta_outlier, valor):\n",
    "    # Cálculo de outlier através do Método Tuckey\n",
    "    eh_outlier_menor = valor < q1 - delta_outlier \n",
    "    eh_outlier_maior = valor > q3 + delta_outlier\n",
    "    \n",
    "    # Se o valor for outlier é necessário deixar o valor vazio\n",
    "    if eh_outlier_menor or eh_outlier_maior:\n",
    "        valor_novo = np.nan\n",
    "    else:\n",
    "        # Caso do valor não ser outlier\n",
    "        valor_novo = valor\n",
    "\n",
    "    return valor_novo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------- Tarefa 5 --------------------------------------------------------- #\n",
    "\n",
    "# Função para criar um relatório para as variáveis qualitativas\n",
    "def criar_relatorio_colunas_qualitativas(df_unificado):\n",
    "    shapes = df_unificado.shape\n",
    "    colunas_qualitativas = pegar_colunas_qualitativas(df_unificado)\n",
    "\n",
    "    # Para cada coluna de variáveis qualitativas será criado um DataFrame para printar o seu respectivo relatório\n",
    "    dicionario_dados = {}\n",
    "    for coluna in colunas_qualitativas:\n",
    "        # Para cada variável única na coluna em estudo é preciso calcular suas frequências\n",
    "        for variavel_quali in sorted(df_unificado[coluna].unique()):\n",
    "            # Função para retornar a lista das freqs calculadas\n",
    "            dicionario_dados[variavel_quali] = calcular_frequencia(df_unificado, coluna, variavel_quali, shapes[0])\n",
    "        # Construção do Data Frame a partir de um dicionário de daods\n",
    "        df_temp = pd.DataFrame.from_dict(dicionario_dados, orient='index', columns=['Freq. Abs.', 'Freq. Rel.', 'Freq. Rel (%)'])\n",
    "        # Construir a última coluna de freq acumulada\n",
    "        df_temp.loc[:, 'Freq. Rel. Ac.'] = df_temp['Freq. Rel (%)'].cumsum()\n",
    "        # Printar o DataFrame\n",
    "        print(coluna)\n",
    "        display(round(df_temp, 2))\n",
    "        dicionario_dados = {}\n",
    "\n",
    "\n",
    "# Função para pegar as colunas com dados qualitativos\n",
    "def pegar_colunas_qualitativas(df_unificado):\n",
    "    df_unificado.dropna(inplace=True)\n",
    "    colunas_qualitativas = [coluna for coluna in df_unificado.select_dtypes(include='object').columns]\n",
    "    # Colunas numéricas que representam variáveis qualitativas\n",
    "    colunas_qualitativas.extend(['Agricultural Household indicator', 'Electricity', 'ID'])\n",
    "    colunas_qualitativas.sort()\n",
    "\n",
    "    return colunas_qualitativas\n",
    "\n",
    "# Função para calcular os valores de frequência de cada variável qualitativa\n",
    "def calcular_frequencia(df_unificado, coluna, variavel_quali, numero_linhas):\n",
    "    # Filtrar a coluna por cada variável única da sua série\n",
    "    mascara_variavel_qualitativa = df_unificado[coluna] == variavel_quali\n",
    "    # Calcular as frequências\n",
    "    freq_abs = df_unificado.loc[mascara_variavel_qualitativa, coluna].count()\n",
    "    freq_rel = freq_abs/numero_linhas\n",
    "\n",
    "    return [freq_abs, freq_rel, freq_rel*100]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------- Tarefa 6 --------------------------------------------------------- #\n",
    "\n",
    "# Função para criar um arquivo csv que resume somente os dados que a renda esteja entre os 10% maiores da base\n",
    "def cria_csv_alta_renda(df_unificado):\n",
    "    mascara_alta_renda, _ = pegar_quantil_renda(df_unificado)\n",
    "\n",
    "    df_alta_renda = df_unificado.loc[mascara_alta_renda].sort_values(by='Total Household Income', ascending=False)\n",
    "    df_alta_renda.reset_index(drop=True,inplace=True)\n",
    "    df_alta_renda.to_csv(folder_class_path + '/dados_alta_renda.csv', sep=';', encoding='utf-8-sig')\n",
    "\n",
    "def pegar_quantil_renda(df_unificado):\n",
    "    quantil_90 = df_unificado['Total Household Income'].quantile(0.9)\n",
    "    mascara_alta_renda = df_unificado['Total Household Income'] > quantil_90\n",
    "    return mascara_alta_renda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------- Tarefa 7 --------------------------------------------------------- #\n",
    "def criar_dummies(df_unificado, qtd_colunas):\n",
    "    colunas_qualitativas = pegar_colunas_qualitativas(df_unificado)\n",
    "    df_dummies = pd.get_dummies(df_unificado, columns=colunas_qualitativas[:qtd_colunas])\n",
    "    df_dummies.drop(columns=colunas_qualitativas, errors='ignore',inplace=True)\n",
    "    \n",
    "    return df_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------- Tarefa 8 --------------------------------------------------------- #\n",
    "def comparar_medias(df_unificado, qtd_colunas_qualitativas):\n",
    "    df_dummies = criar_dummies(df_unificado, qtd_colunas_qualitativas)\n",
    "    df_dummies = insere_coluna_classificacao_renda(df_dummies, df_unificado)\n",
    "\n",
    "    display(df_dummies.groupby('classificacao_mais_ricos').mean().style.format('{:.2f}').highlight_max(color='green'))\n",
    "\n",
    "\n",
    "def insere_coluna_classificacao_renda(df_dummies, df_unificado):\n",
    "    df_dummies['classificacao_mais_ricos'] = pegar_quantil_renda(df_unificado)\n",
    "    df_dummies.loc[df_dummies['classificacao_mais_ricos'] == True, 'classificacao_mais_ricos'] = 'Renda Acima de 10%'\n",
    "    df_dummies.loc[df_dummies['classificacao_mais_ricos'] == False, 'classificacao_mais_ricos'] = 'Demais Rendas'\n",
    "    return df_dummies\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarefa 1\n",
    "pd.options.mode.chained_assignment = None\n",
    "df_demografico, df_renda_gastos, df_bens = receber_bases()\n",
    "df_unificado = unificar_bases(df_demografico, df_renda_gastos, df_bens)\n",
    "pd.options.mode.chained_assignment = 'warn'\n",
    "\n",
    "comparar_medias(df_unificado, 3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d3337ba5168f4c0be55a76bf4408a32171a059c23933e013fbbd8f36ebd1d40"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
